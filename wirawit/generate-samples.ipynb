{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "sys.path.append('../')\n",
    "from shared.models.basic_lstm import BasicLSTM\n",
    "from shared.process.pa4_dataloader import build_all_loaders\n",
    "from shared.process.PA4Trainer import get_computing_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLSTM(\n",
       "  (lstm): LSTM(93, 300, batch_first=True)\n",
       "  (h2o): Linear(in_features=300, out_features=93, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computing_device = get_computing_device()\n",
    "all_loaders, infos = build_all_loaders('../pa4Data/')\n",
    "\n",
    "char2ind = infos['char_2_index']\n",
    "ind2char = infos['index_2_char']\n",
    "\n",
    "model = BasicLSTM(len(char2ind), 300, len(char2ind))\n",
    "model.load_state_dict(torch.load('./lstm300adam0.001/model_state.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "model.to(computing_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_str = \"<start>\"\n",
    "prime_tensor = torch.zeros(len(prime_str), len(char2ind)).to(computing_device)\n",
    "        \n",
    "for i in range(len(prime_str)):\n",
    "    char = prime_str[i]\n",
    "    prime_tensor[i, char2ind[char]] = 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from a category and starting letter\n",
    "def sample(model, T=None, max_length = 2000, stop_on_end_tag=False):\n",
    "    \n",
    "    sample_music = \"\"\n",
    "    \n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        model.reset_hidden(computing_device)\n",
    "        \n",
    "        # Prime with <start>, hidden state is now ready\n",
    "        logits = model(prime_tensor.unsqueeze(dim=0))[-1]\n",
    "        \n",
    "        i = 0\n",
    "        while i < max_length:\n",
    "            res_ind = None\n",
    "            if T is None:\n",
    "                res_ind = np.argmax(logits).item()\n",
    "            else:\n",
    "                prob = np.array(F.softmax(logits/T, dim=0))\n",
    "                res_ind = np.random.choice(len(char2ind), 1, p=prob)[0]\n",
    "            final_char = ind2char[res_ind]            \n",
    "            sample_music += final_char\n",
    "            i+=1\n",
    "            if i % 50 == 0:\n",
    "                print(i)\n",
    "                \n",
    "            if stop_on_end_tag and (sample_music[-5:] == \"<end>\" or sample_music[-7:] == \"<start>\"):\n",
    "                print(\"Found <end>, stop making music at i = {0}.\".format(i))\n",
    "                break\n",
    "                \n",
    "            next_char_tensor = torch.zeros(len(char2ind)).to(computing_device)\n",
    "            next_char_tensor[res_ind] = 1\n",
    "            next_char_tensor = next_char_tensor.view(1,1,-1)\n",
    "            logits = model(next_char_tensor)[-1]\n",
    "\n",
    "        return sample_music#.split(\"<end>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "Found <end>, stop making music at i = 240.\n"
     ]
    }
   ],
   "source": [
    "m1 = sample(model, T=0.8, max_length=2_000, stop_on_end_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X:77\n",
      "T:Meis Erlister Dol achaine Crossey, The\n",
      "T:Callyce Rither, The\n",
      "R:polka\n",
      "H:See also #77, #16\n",
      "D:Replay Danole, Tun Fons Doler\n",
      "Z:id:hn-polka-75\n",
      "M:2/4\n",
      "L:1/8\n",
      "K:D\n",
      "E>A BA|FA AB/c/|dA AB|^c/d/ eg gf|eg fg|fd Bd|Bd dB|AB cd|ef a>g|fA A2:|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m1 = m1.replace(\"<end>\", \"\")\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyabc\n",
    "def is_valid_abc_syntax(sample):\n",
    "    try:\n",
    "        _ = pyabc.Tune(sample)\n",
    "        # Valid\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Invalid abc syntax!\", e)\n",
    "        return False\n",
    "is_valid_abc_syntax(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X:71\n",
      "T:Bolly Berder Crosser Polka\n",
      "R:polka\n",
      "Z:id:hn-polka-77\n",
      "Z:id:hn-polka\n",
      "7:Mary Bergin: Feadoga Stain 21\n",
      "Z:id:hn-polka-92\n",
      "M:2/4\n",
      "L:1/8\n",
      "K:A\n",
      "A>B cE|cB Bc|ed dB|AB c/B/A/B/|AF DF|AF AB|1 d2 B2:|2 d2 de||\n",
      "|:fbrea af|ef/e/ cd|ef g2|dB cB|AB cd|ef e2|dB AB|1 BA GA:|2 A2 D2:|2 d2 d2||\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in m1.split(\"<end>\"):\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = \"\"\"<start>\n",
    "X:1\n",
    "T:Be so nom Bangis of tom the Corne to Malse #158\n",
    "Z:id:hn-polka-89\n",
    "M:2/4\n",
    "L:1/8\n",
    "K:A\n",
    "A>A B/A/G/A/|BA BA/B/|dB dB/B/|AB cB/A/|GA Bd/e/|dB B/A/G/A/|1 AG GB/c/:|2 BG GA||\n",
    "P:variation 29\n",
    "D:D Danne\n",
    "Z:id:hn-polka-86\n",
    "M:2/4\n",
    "L:1/8\n",
    "K:D\n",
    "de dB|AB cB|AB BA|BA BA|BA Bd|ef/e/ dB|1 BA AB/c/:|2 BA Bd|e2 ef|ed e>f|ed cB|A2 AB/c/|dB AB/c/|ed cB|cA AB/c/|dB AB/c/|\n",
    "dB Bd/B/|dB BA/B/|dB AB/c/|Bd Bc/d/|eA cB/A/|BA GB/d/|ef ec/e/|fd dB|AB AG|\n",
    "AB AB/c/|dB AB|Bc AB/c/|dB AB/A/|BA BG/B/|AB cB/A/|BA Bd/e/|fd ef|fe fd|ef ed|e2 ed/B/|A2 AG||\n",
    "<end>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_str = m1\n",
    "input = torch.zeros(len(cur_str), len(char2ind)).to(computing_device)\n",
    "        \n",
    "for i in range(len(cur_str)-1):\n",
    "    char = cur_str[i]\n",
    "    input[i, char2ind[char]] = 1\n",
    "input.unsqueeze_(0)\n",
    "lstm_out = model.lstm(input, model.hidden)[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 100)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_at_k(k, save_fig=False, path_to_save=None):\n",
    "    N_PER_ROW = 20\n",
    "\n",
    "    def scale(x):\n",
    "        return ((x - x.min())/(x.max() - x.min())) * 2 - 1\n",
    "    lstm_out_k = lstm_out[:,k]\n",
    "\n",
    "    n_activations, n_hiddens = lstm_out.shape\n",
    "    n_activations = n_activations\n",
    "    target_length = int(np.ceil(n_activations / N_PER_ROW) * N_PER_ROW)\n",
    "    n_padding = target_length - n_activations\n",
    "\n",
    "    num_rows = target_length//N_PER_ROW\n",
    "    final_frame = scale(np.array(list(lstm_out_k.flatten()) + list(np.zeros(n_padding))).reshape((target_length//N_PER_ROW, N_PER_ROW)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    im = ax.imshow(final_frame, cmap='RdBu_r')\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(N_PER_ROW))\n",
    "    ax.set_yticks(np.arange(num_rows))\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(num_rows):\n",
    "        for j in range(N_PER_ROW):\n",
    "            true_pos = i * N_PER_ROW + j\n",
    "            if true_pos < len(cur_str):\n",
    "                char = cur_str[true_pos]\n",
    "                if char == \"\\n\":\n",
    "                    char = \"\\\\n\"\n",
    "                text = ax.text(j, i, char,\n",
    "                               ha=\"center\", va=\"center\", color=\"black\", fontsize=12)\n",
    "\n",
    "    ax.set_title(\"Activation map\")\n",
    "\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_fig:\n",
    "        plt.savefig(os.path.join(path_to_save, 'heatmap-{0}.png'.format(k)), bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2736c1bd314ff392c642957a6d6d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH_TO_SAVE = './figs'\n",
    "os.makedirs(PATH_TO_SAVE, exist_ok=True)\n",
    "N_K = lstm_out.shape[1]\n",
    "for i in tqdm(range(N_K)):\n",
    "    heatmap_at_k(i, save_fig=True, path_to_save=PATH_TO_SAVE)\n",
    "#     print(\"Done\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
